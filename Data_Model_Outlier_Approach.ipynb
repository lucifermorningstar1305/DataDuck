{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef7ac2cd-5dc9-487d-a83b-fb87f5bf385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNotebook color scheme\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAABlCAYAAAB5q1VcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC+0lEQVR4nO3aMWobeRjG4U9SjMBEEhjSCKlyt1WOsTfYOicROcleY4+RE7iwQE06Kbgx8myxeKugeP447zD289Qzw8cnoR8zmknXdV0BwG82HXoAAN4HwQEgQnAAiBAcACIEB4AIwQEgQnAAiPjQeuLT01MdDodaLBY1mUxecyYARqLrujqdTrVer2s6vXwP0xycw+FQ2+229XQA3pD9fl+bzebiMc3BWSwWVVX19+fPdT2btV7m3fnz06ehRxin3W7oCUbprz++Dj3C6Hz/5/vQI4zK+eFc3758+78JlzQH5/kx2vVsJjg9LK+uhh5hnD5+HHqCUbpa+r71Nbv2e9biJX+teGkAgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgAjBASBCcACIEBwAIgQHgIgPrSd2XVdVVQ/n86sN8x4cHx+HHmGcfvwYeoJRejz6vvV1fvCb1sfzvp6bcMmke8lRP3F3d1e3t7ctpwLwxuz3+9psNhePab7Dubm5qaqq+/v7Wq1WrZd5V47HY22329rv97VcLoceZzTsrT87a2Nv/XVdV6fTqdbr9S+PbQ7OdPrf3z+r1coH09NyubSzBvbWn521sbd+XnrT4aUBACIEB4CI5uDM5/Pa7XY1n89fc543zc7a2Ft/dtbG3n6v5rfUAKAPj9QAiBAcACIEB4AIwQEgQnAAiBAcACIEB4AIwQEg4l+NhHJoUsf0ogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Union, List, Tuple, Any, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import auc, precision_recall_curve, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from IPython.display import display_latex, display_markdown\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from datetime import datetime\n",
    "from colorama import Fore, Style\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class clr:\n",
    "    S = Style.BRIGHT + Fore.RED\n",
    "    E = Style.RESET_ALL\n",
    "\n",
    "MY_COLORS = [\"#b33636\", \"#ff4d4d\", \"#ffd3d3\", \"#4dff4d\", \"#36b336\"]\n",
    "MY_CMAP = ListedColormap(MY_COLORS)\n",
    "print(clr.S+\"Notebook color scheme\"+clr.E)\n",
    "sns.palplot(sns.color_palette(MY_COLORS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8306361-5c9f-487f-a5b0-66fbe6eb4bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>papaId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>eventType</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>MessageID</th>\n",
       "      <th>Payload</th>\n",
       "      <th>path</th>\n",
       "      <th>hops</th>\n",
       "      <th>duckType</th>\n",
       "      <th>corrupted_device</th>\n",
       "      <th>corrupted_message</th>\n",
       "      <th>charging</th>\n",
       "      <th>counter</th>\n",
       "      <th>full</th>\n",
       "      <th>volts</th>\n",
       "      <th>board_temp</th>\n",
       "      <th>packet_loss</th>\n",
       "      <th>is_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OWL_HQ</td>\n",
       "      <td>2022-03-12 0:00:10</td>\n",
       "      <td>health</td>\n",
       "      <td>IRDUCK01</td>\n",
       "      <td>UV16</td>\n",
       "      <td>Counter:58 Charging:1 Full:0 Volts:-3.00 Temp:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OWL_HQ</td>\n",
       "      <td>2022-03-12 0:01:47</td>\n",
       "      <td>health</td>\n",
       "      <td>HEALTHDK</td>\n",
       "      <td>DE1R</td>\n",
       "      <td>Counter:61 Charging:1 Full:0 Volts:-3.00 Temp:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OWL_HQ</td>\n",
       "      <td>2022-03-12 0:02:10</td>\n",
       "      <td>health</td>\n",
       "      <td>IRDUCK01</td>\n",
       "      <td>6T9P</td>\n",
       "      <td>Counter:59 Charging:1 Full:0 Volts:-3.00 Temp:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWL_HQ</td>\n",
       "      <td>2022-03-12 0:03:48</td>\n",
       "      <td>health</td>\n",
       "      <td>HEALTHDK</td>\n",
       "      <td>UVR4</td>\n",
       "      <td>Counter:62 Charging:1 Full:0 Volts:-3.00 Temp:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OWL_HQ</td>\n",
       "      <td>2022-03-12 0:05:47</td>\n",
       "      <td>health</td>\n",
       "      <td>HEALTHDK</td>\n",
       "      <td>DVI7</td>\n",
       "      <td>Counter:63 Charging:1 Full:0 Volts:-3.00 Temp:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   papaId           createdAt eventType  DeviceID MessageID  \\\n",
       "0  OWL_HQ  2022-03-12 0:00:10    health  IRDUCK01      UV16   \n",
       "1  OWL_HQ  2022-03-12 0:01:47    health  HEALTHDK      DE1R   \n",
       "2  OWL_HQ  2022-03-12 0:02:10    health  IRDUCK01      6T9P   \n",
       "3  OWL_HQ  2022-03-12 0:03:48    health  HEALTHDK      UVR4   \n",
       "4  OWL_HQ  2022-03-12 0:05:47    health  HEALTHDK      DVI7   \n",
       "\n",
       "                                             Payload  path  hops  duckType  \\\n",
       "0  Counter:58 Charging:1 Full:0 Volts:-3.00 Temp:...   NaN     1         2   \n",
       "1  Counter:61 Charging:1 Full:0 Volts:-3.00 Temp:...   NaN     1         2   \n",
       "2  Counter:59 Charging:1 Full:0 Volts:-3.00 Temp:...   NaN     1         2   \n",
       "3  Counter:62 Charging:1 Full:0 Volts:-3.00 Temp:...   NaN     1         2   \n",
       "4  Counter:63 Charging:1 Full:0 Volts:-3.00 Temp:...   NaN     1         2   \n",
       "\n",
       "   corrupted_device  corrupted_message  charging  counter  full  volts  \\\n",
       "0                 0                  0         1       58     0   -3.0   \n",
       "1                 0                  0         1       61     0   -3.0   \n",
       "2                 0                  0         1       59     0   -3.0   \n",
       "3                 0                  0         1       62     0   -3.0   \n",
       "4                 0                  0         1       63     0   -3.0   \n",
       "\n",
       "   board_temp  packet_loss  is_lost  \n",
       "0        -3.0            1        0  \n",
       "1        -3.0            2        1  \n",
       "2        -3.0            1        0  \n",
       "3        -3.0            1        0  \n",
       "4        -3.0            1        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/clean_health - clean_health.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f0196-7ecf-4e1f-89f1-0f6d2b7c7355",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41026591-e4de-45f0-a4c5-273ec18c66ae",
   "metadata": {},
   "source": [
    "## - Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b59d52b-91c9-4b69-86a4-d92a85c17655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m===== Training Data Information =====\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Number of records : $87828$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Number of attributes : $6$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[31m===== Test Data Information =====\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Number of records : $4623$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Number of attributes : $6$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_mod = df[[\"DeviceID\", \"hops\", \"charging\", \"counter\", \"volts\", \"board_temp\", \"is_lost\"]]\n",
    "\n",
    "label_device = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_mod[\"DeviceID\"] = label_device.fit_transform(df_mod[\"DeviceID\"])\n",
    "# scaled_feat = scaler.fit_transform(df_mod[[\"hops\", \"counter\", \"volts\", \"board_temp\"]])\n",
    "# df_mod[[\"hops\", \"counter\", \"volts\", \"board_temp\"]] = scaled_feat\n",
    "\n",
    "df_train, df_test = train_test_split(df_mod, test_size=0.05, random_state=42, stratify=df[\"is_lost\"])\n",
    "print(clr.S+\"===== Training Data Information =====\"+clr.E)\n",
    "print(\"\\n\\n\")\n",
    "display_markdown(f\"Number of records : ${df_train.shape[0]}$\", raw=True)\n",
    "display_markdown(f\"Number of attributes : ${df_train.shape[1] - 1}$\", raw=True)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(clr.S+\"===== Test Data Information =====\"+clr.E)\n",
    "print(\"\\n\\n\")\n",
    "display_markdown(f\"Number of records : ${df_test.shape[0]}$\", raw=True)\n",
    "display_markdown(f\"Number of attributes : ${df_test.shape[1] - 1}$\", raw=True)\n",
    "\n",
    "\n",
    "scaled_feat = scaler.fit_transform(df_train[[\"hops\", \"counter\", \"volts\", \"board_temp\"]])\n",
    "df_train[[\"hops\", \"counter\", \"volts\", \"board_temp\"]] = scaled_feat\n",
    "df_test[[\"hops\", \"counter\", \"volts\", \"board_temp\"]] = scaler.transform(df_test[[\"hops\", \"counter\", \"volts\", \"board_temp\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c903ba-e5b4-476e-bfd9-688f08b39439",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop('is_lost', axis=1).values, df_train['is_lost'].values\n",
    "X_test, y_test = df_test.drop('is_lost', axis=1).values, df_test['is_lost'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3657a1-d48b-4468-9272-458212f409d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def confusion_display(y_true:np.ndarray, y_pred:np.ndarray) -> None:\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    \n",
    "    grp = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
    "    annot = [f\"{x1}\\n{np.round(x2, 2)}\" for x1, x2 in zip(grp, conf_mat.flatten())]\n",
    "    annot = np.array(annot).reshape(2, 2)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.set_title(\"Confusion Matrix\", fontsize=16, weight=\"bold\")\n",
    "    sns.heatmap(conf_mat, annot=annot, fmt=\"\", ax=ax,\n",
    "                cmap=MY_CMAP, cbar=True, linewidths=2.0)\n",
    "    ax.set_xticklabels([\"No LOSS\", \"LOSS\"])\n",
    "    ax.set_yticklabels([\"No LOSS\", \"LOSS\"])\n",
    "    ax.set_xlabel(\"Predictions\")\n",
    "    ax.set_ylabel(\"Acutal\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94d14260-d71d-494c-906e-6c8edeca6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df[\"is_lost\"].values)\n",
    "class_weight_0 = 1 - (neg / (neg + pos))\n",
    "class_weight_1 = 1 - (pos/(neg + pos))\n",
    "\n",
    "# class_wts = {0:class_weight_0, 1:class_weight_1}\n",
    "class_wts = np.array([class_weight_0, class_weight_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8be0f0-48b6-4354-b584-d0dc93e22262",
   "metadata": {},
   "source": [
    "## - Functions for Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d5a76e-ee61-462a-a601-854e327888d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(y_true:np.ndarray, y_pred:np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    This function returns the AUC of precision-recall curve.\n",
    "    \n",
    "    :param y_true: the true labels.\n",
    "    :param y_pred: the predicted labels.\n",
    "    \n",
    "    :returns: the AUC of the precision-recall curve.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prec, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    # score = auc(recall, prec)\n",
    "    score = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54bfc2de-5352-47cb-b52d-617ec457f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial:optuna.Trial, data:Tuple, model_name:str, class_wts:np.ndarray=None) -> float:\n",
    "    \"\"\"\n",
    "    The objective function to be used for optuna\n",
    "    \n",
    "    :param trial: the optuna trial\n",
    "    :param data: the (X,y) for the model training.\n",
    "    :param model_name: the name of the model\n",
    "    :param class_wts: the class weights for the classes (if any)\n",
    "    \n",
    "    :returns: the score\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name not in [\"OneClassSVM\", \"IF\", \"LOF\"]:\n",
    "        raise Exception(f\"Expected values for model_name to be either of {'/'.join(model_name)}. Found {model_name}.\")\n",
    "        \n",
    "    if model_name == \"OneClassSVM\":\n",
    "        params_dist = {\n",
    "            \"nu\" : trial.suggest_float(\"nu\", 0.0, 1.0),\n",
    "            \"kernel\":trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"sigmoid\"]),\n",
    "            \"gamma\" : trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "        }\n",
    "\n",
    "    elif model_name == \"KNN\":\n",
    "        params_dist = {\n",
    "            \"n_neighbors\" : trial.suggest_int(\"n_neighbors\", 1, 100, step=2),\n",
    "            \"metric\" : trial.suggest_categorical(\"metric\", ['minkowski', 'euclidean', 'cosine'])            \n",
    "        }\n",
    "    elif model_name == \"IF\":\n",
    "        params_dist = {\n",
    "            \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 10000, step=100),\n",
    "            \"contamination\": trial.suggest_float(\"contamination\", 0, 0.5)\n",
    "        }\n",
    "    \n",
    "    models = {\n",
    "        \"OneClassSVM\" : OneClassSVM,\n",
    "        \"LOF\":LocalOutlierFactor,\n",
    "        \"IF\": IsolationForest\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    X, y = data\n",
    "    \n",
    "    val_scores = list()\n",
    "    \n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        \n",
    "        trainX, trainy = X[train_idx], y[train_idx]\n",
    "        valX, valy = X[val_idx], y[val_idx]\n",
    "        \n",
    "        \n",
    "        sample_wt = np.where(trainy == 1, class_wts[1], class_wts[0])\n",
    "        \n",
    "        if model_name == \"IF\":\n",
    "            model = models[model_name](random_state=42, n_jobs=-1, verbose=1, **params_dist)\n",
    "            model.fit(trainX, sample_weight=sample_wt)\n",
    "            \n",
    "        elif model_name == \"LOF\":\n",
    "            model = models[model_name](n_jobs=-1, **params_dist)\n",
    "            model.fit(trainX)\n",
    "        else:\n",
    "            model = models[model_name](verbose=1, **params_dist)\n",
    "            model.fit(trainX, sample_weight=sample_wt)\n",
    "        \n",
    "        val_preds = model.predict(valX)\n",
    "        val_preds = np.where(val_preds == -1, 1, 0)\n",
    "        val_score = score_model(valy, val_preds)\n",
    "        \n",
    "        val_scores.append(np.round(val_score, 4))\n",
    "    \n",
    "    return np.mean(val_scores)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90260c08-7c87-41cf-837a-c782531662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stop_check(study:optuna.study.Study, trial:optuna.trial.Trial, rounds:int=5) -> None:\n",
    "    \"\"\"\n",
    "    This function acts as a early stopping criteria for optuna.\n",
    "    \n",
    "    :param study: the optuna study.\n",
    "    :param trial: the optuna trial.\n",
    "    :param rounds: number of steps to follow before early-stopping.\n",
    "    \n",
    "    \"\"\"\n",
    "    curnt_trl_num = trial.number\n",
    "    bst_trl_num = study.best_trial.number\n",
    "    diff = curnt_trl_num - bst_trl_num\n",
    "    \n",
    "    if diff >= rounds:\n",
    "        print(clr.S+\"Early Stopping detected !!\"+clr.E)\n",
    "        study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b3ff4e-07c1-4b11-a2b1-0bd1adce218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_cv(train:Tuple, test:Tuple, model_name:str, class_wts:np.ndarray=None, reps:int=5, early_stop_rounds:int=5) -> Dict:\n",
    "    \"\"\"\n",
    "    This function performs the repeated cross validation of the model.\n",
    "    \n",
    "    :param data: the training data.\n",
    "    :param test: the test data.\n",
    "    :param model_name: The type of model to train. e.g. SVC for svm classifier.\n",
    "    :param class_wts: the class weights for individual classes (if any)\n",
    "    :param reps: number of repetetions to perform.\n",
    "    :param early_stop_rounds: number of steps to check before early stopping.\n",
    "    \n",
    "    :returns: repeated cross validation score & best parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {\n",
    "        \"OneClassSVM\" : OneClassSVM,\n",
    "        \"LOF\":LocalOutlierFactor,\n",
    "        \"IF\": IsolationForest\n",
    "    }\n",
    "    \n",
    "    details = {}\n",
    "    \n",
    "    for rep in range(reps):\n",
    "        print(clr.S+\"Repetetion - \"+clr.E+str(rep + 1))\n",
    "        \n",
    "        sampler = optuna.samplers.TPESampler(seed=1234)\n",
    "        study = optuna.create_study(\n",
    "            study_name=f\"repeated_cv_{model_name}_rep_{rep}\" if class_wts is None else f\"repeated_cv_{model_name}_classwts_rep_{rep}\",\n",
    "            direction=\"maximize\",\n",
    "            sampler = sampler,\n",
    "            load_if_exists=True,\n",
    "            storage=\"sqlite:///study_outlier_approach.db\"\n",
    "        )\n",
    "        \n",
    "        concat_data = np.concatenate(train, axis=1)\n",
    "        np.random.shuffle(concat_data)\n",
    "        X, y = concat_data[:,:-1], concat_data[:, -1].flatten() \n",
    "        func = lambda trial: objective(trial, (X, y), model_name, class_wts=class_wts)\n",
    "        \n",
    "        study.optimize(func,\n",
    "                      n_trials=50,\n",
    "                      callbacks=[partial(early_stop_check, rounds=early_stop_rounds)])\n",
    "        \n",
    "        print(clr.S+\"Number of trials finished out of 50: \"+clr.E+str(len(study.trials))+clr.S+\"\\n Best trial : \"+clr.E+str(study.best_trial.value))\n",
    "        \n",
    "        best_hyp = dict()\n",
    "        for k, v in study.best_trial.params.items():\n",
    "            best_hyp[k] = v\n",
    "        \n",
    "        sample_wt = np.where(train[1].flatten() == 1, class_wts[1], class_wts[0])\n",
    "\n",
    "        if model_name == \"IF\":\n",
    "            model = models[model_name](random_state=42, n_jobs=-1, **best_hyp)\n",
    "            model.fit(train[0], sample_weight=sample_wt)\n",
    "            \n",
    "        elif model_name == \"LOF\":\n",
    "            model = models[model_name](n_jobs=-1, **best_hyp)\n",
    "            model.fit(train[0])\n",
    "        else:\n",
    "            model = models[model_name](**best_hyp)\n",
    "            model.fit(train[0], sample_weight=sample_wt)\n",
    "            \n",
    "        preds = np.where(model.predict(test[0]) == -1, 1, 0)\n",
    "        \n",
    "        score = score_model(test[1], preds)\n",
    "        details[f\"rep-{rep+1}\"] = {\"best_hyp\":best_hyp, \"score\":score}\n",
    "    \n",
    "    return details\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083c014-cf14-47a4-aa73-2e424abbf50f",
   "metadata": {},
   "source": [
    "## - Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df8730ef-44f7-4e4e-b4f6-1d9b7274d84c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-25 12:35:42,345]\u001b[0m Using an existing study with name 'repeated_cv_IF_classwts_rep_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mRepetetion - \u001b[0m1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    3.5s remaining:   17.4s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    3.3s remaining:   16.5s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    3.2s remaining:   16.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    3.6s remaining:   18.2s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    3.4s remaining:   16.9s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    3.4s finished\n",
      "\u001b[32m[I 2023-01-25 12:37:16,880]\u001b[0m Trial 29 finished with value: 0.19839999999999997 and parameters: {'n_estimators': 1600, 'contamination': 0.4564205283069688}. Best is trial 17 with value: 0.33596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mEarly Stopping detected !!\u001b[0m\n",
      "\u001b[1m\u001b[31mNumber of trials finished out of 50: \u001b[0m30\u001b[1m\u001b[31m\n",
      " Best trial : \u001b[0m0.33596\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m isof_details \u001b[38;5;241m=\u001b[39m \u001b[43mrepeated_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_wts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_wts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 54\u001b[0m, in \u001b[0;36mrepeated_cv\u001b[0;34m(train, test, model_name, class_wts, reps, early_stop_rounds)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     53\u001b[0m     model \u001b[38;5;241m=\u001b[39m models[model_name](random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_hyp)\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_wt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     57\u001b[0m     model \u001b[38;5;241m=\u001b[39m models[model_name](n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_hyp)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/ensemble/_iforest.py:322\u001b[0m, in \u001b[0;36mIsolationForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# else, define offset_ wrt contamination parameter\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontamination)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/ensemble/_iforest.py:414\u001b[0m, in \u001b[0;36mIsolationForest.score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Take the opposite of the scores as bigger is better (here less\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# abnormal)\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_chunked_score_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/ensemble/_iforest.py:445\u001b[0m, in \u001b[0;36mIsolationForest._compute_chunked_score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    441\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_samples, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sl \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# compute score on the slices of test samples:\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     scores[sl] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_score_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43msl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/ensemble/_iforest.py:473\u001b[0m, in \u001b[0;36mIsolationForest._compute_score_samples\u001b[0;34m(self, X, subsample_features)\u001b[0m\n\u001b[1;32m    469\u001b[0m     node_indicator \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mdecision_path(X_subset)\n\u001b[1;32m    470\u001b[0m     n_samples_leaf \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mn_node_samples[leaves_index]\n\u001b[1;32m    472\u001b[0m     depths \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 473\u001b[0m         np\u001b[38;5;241m.\u001b[39mravel(\u001b[43mnode_indicator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;241m+\u001b[39m _average_path_length(n_samples_leaf)\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m denominator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m*\u001b[39m _average_path_length([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples_])\n\u001b[1;32m    478\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;66;03m# For a single training sample, denominator and depth are 0.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# Therefore, we set the score manually to 1.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[1;32m    484\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:611\u001b[0m, in \u001b[0;36m_cs_matrix.sum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m    608\u001b[0m res_dtype \u001b[38;5;241m=\u001b[39m get_sum_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    609\u001b[0m ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mres_dtype)\n\u001b[0;32m--> 611\u001b[0m major_index, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_minor_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m ret[major_index] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    613\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ascontainer(ret)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646\u001b[0m, in \u001b[0;36m_cs_matrix._minor_reduce\u001b[0;34m(self, ufunc, data)\u001b[0m\n\u001b[1;32m    644\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    645\u001b[0m major_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflatnonzero(np\u001b[38;5;241m.\u001b[39mdiff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr))\n\u001b[0;32m--> 646\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduceat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdowncast_intp_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmajor_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m major_index, value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "isof_details = repeated_cv((X_train, y_train.reshape(-1, 1)), \n",
    "                          (X_test, y_test), \"IF\", class_wts=class_wts, reps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060215f-cc34-4ff0-a7e7-bfaa57c80ead",
   "metadata": {},
   "source": [
    "## - OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5334c0-ecf6-4aa7-bbad-6dea794d1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class_svm_details = repeated_cv((X_train, y_train.reshape(-1, 1)), \n",
    "                                    (X_test, y_test), \"OneClassSVM\", reps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee9762-bf7a-40d7-a063-3d610c486b00",
   "metadata": {},
   "source": [
    "## - Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cac5c-f4a3-4fb5-b343-da6155039ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_class_details = repeated_cv((X_train, y_train.reshape(-1, 1)),\n",
    "                               (X_test, y_test), \"LOF\", reps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e741f68-aa54-41d9-829b-be3610b70dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
